{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f320ae",
   "metadata": {},
   "source": [
    "# NaiveBayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25027347",
   "metadata": {},
   "source": [
    "### Naive Bayes Theorem:\n",
    "\n",
    "Acoording to the wikipedia, In probability theory and statistics,** Bayes’s theorem** (alternatively *Bayes’s law* or *Bayes’s rule*) describes the probability of an event, based on prior knowledge of conditions that might be related to the event.\n",
    "Mathematically, it can be written as:\n",
    "\n",
    "\n",
    "\n",
    "Where A and B are events and P(B)≠0\n",
    "* P(A|B) is a conditional probability: the likelihood of event A occurring given that B is true.\n",
    "* P(B|A) is also a conditional probability: the likelihood of event B occurring given that A is true.\n",
    "* P(A) and P(B) are the probabilities of observing A and B respectively; they are known as the marginal probability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e5ebaf",
   "metadata": {},
   "source": [
    "Let’s understand it with the help of an example:\n",
    "\n",
    "**The problem statement:**\n",
    "\n",
    "You are planning a picnic today, but the morning is cloudy\n",
    "\n",
    "Oh no! 50% of all rainy days start off cloudy!\n",
    "But cloudy mornings are common (about 40% of days start cloudy)\n",
    "And this is usually a dry month (only 3 of 30 days tend to be rainy, or 10%)\n",
    "What is the chance of rain during the day?\n",
    "\n",
    "We will use Rain to mean rain during the day, and Cloud to mean cloudy morning.\n",
    "\n",
    "The chance of Rain given Cloud is written P(Rain|Cloud)\n",
    "\n",
    "So let's put that in the formula:\n",
    "\n",
    "$P(Rain|Cloud) = \\frac{P(Rain)*P(Cloud|Rain)} {P(Cloud)}$          \n",
    "                      \n",
    " \n",
    "\n",
    "- P(Rain) is Probability of Rain = 10%\n",
    "- P(Cloud|Rain) is Probability of Cloud, given that Rain happens = 50%\n",
    "- P(Cloud) is Probability of Cloud = 40%\n",
    "\n",
    "$P(Rain|Cloud) =  \\frac{(0.1 x 0.5)} {0.4}   = .125$\n",
    "\n",
    "Or a 12.5% chance of rain. Not too bad, let's have a picnic!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da572c5b",
   "metadata": {},
   "source": [
    "**Naïve:** It is called Naïve because it assumes that the occurrence of a certain feature is independent of the occurrence of other features. Such as if the fruit is identified on the bases of color, shape, and taste, then red, spherical, and sweet fruit is recognized as an apple. Hence each feature individually contributes to identify that it is an apple without depending on each other.<br>\n",
    "**Bayes:** It is called Bayes because it depends on the principle of Bayes' Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea3e282",
   "metadata": {},
   "source": [
    "# Problem: \n",
    "To predict whether a new mail based on its content, can be categorized into spam or not-spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49294c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9288101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('spam.tsv',sep='\\t',names=['Class','Message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bc85b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5567 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class                                            Message\n",
       "0      ham  I've been searching for the right words to tha...\n",
       "1     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "2      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "3      ham  Even my brother is not like to speak with me. ...\n",
       "4      ham               I HAVE A DATE ON SUNDAY WITH WILL!!!\n",
       "...    ...                                                ...\n",
       "5562  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5563   ham               Will ü b going to esplanade fr home?\n",
       "5564   ham  Pity, * was in mood for that. So...any other s...\n",
       "5565   ham  The guy did some bitching but I acted like i'd...\n",
       "5566   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5567 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d25da14",
   "metadata": {},
   "source": [
    "# Basic Checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bf66576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5567, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "173b87dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5567 entries, 0 to 5566\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Class    5567 non-null   object\n",
      " 1   Message  5567 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7336169",
   "metadata": {},
   "source": [
    " So no null values are present here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba5d0a3",
   "metadata": {},
   "source": [
    "### Create a column 'Length' to keep the count of characters in present in each record/message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "808ef6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Length'] = data['Message'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9d69c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Message</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!!</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                            Message  Length\n",
       "0   ham  I've been searching for the right words to tha...     196\n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...      61\n",
       "3   ham  Even my brother is not like to speak with me. ...      77\n",
       "4   ham               I HAVE A DATE ON SUNDAY WITH WILL!!!      36"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f3389",
   "metadata": {},
   "source": [
    "### Let's see the counts of each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c55e683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>746</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Message  Length\n",
       "Class                 \n",
       "ham       4821    4821\n",
       "spam       746     746"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a843bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5567.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>80.450153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>59.891023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>910.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Length\n",
       "count  5567.000000\n",
       "mean     80.450153\n",
       "std      59.891023\n",
       "min       2.000000\n",
       "25%      36.000000\n",
       "50%      62.000000\n",
       "75%     122.000000\n",
       "max     910.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63a1a87",
   "metadata": {},
   "source": [
    "Maximum length of a message is 910 in this dataset and minimum length is 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8581b1fd",
   "metadata": {},
   "source": [
    "### The message which has max length of characters.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b34fe4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Message</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>ham</td>\n",
       "      <td>For me the love should start with attraction.i...</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class                                            Message  Length\n",
       "1080   ham  For me the love should start with attraction.i...     910"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['Length']==910]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9806eff0",
   "metadata": {},
   "source": [
    "### The message which has minimum length of characters.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "902ca29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Message</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4493</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5352</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class Message  Length\n",
       "1920   ham      Ok       2\n",
       "3046   ham      Ok       2\n",
       "4493   ham      Ok       2\n",
       "5352   ham      Ok       2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['Length'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac3ef820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080    For me the love should start with attraction.i...\n",
       "Name: Message, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Length']==910]['Message']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da86aeaa",
   "metadata": {},
   "source": [
    "# Text Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989a2ae4",
   "metadata": {},
   "source": [
    "Creating an object for the target variable and independent variable using values attribute to convert a series into an array.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "708c63e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_obj = data['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53dc6dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# msg_obj = data['Message'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8c5a8b",
   "metadata": {},
   "source": [
    "# Handling Categorical Column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4a03bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['Class'] == 'ham','Class'] = 1\n",
    "data.loc[data['Class'] == 'spam','Class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08f3b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a4f17bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatype for y is object. lets convert it into int\n",
    "data['Class']=data['Class'].astype('int')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bc1fdc",
   "metadata": {},
   "source": [
    "# Step-I: \n",
    "Is to remove punctuation from the text/message/record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb2110af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19a9ce4",
   "metadata": {},
   "source": [
    "*  here we've punctuation signs according to python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad05ea7b",
   "metadata": {},
   "source": [
    "### Let's remove the punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7327499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf692ce",
   "metadata": {},
   "source": [
    "### We just created a simple function to remove punctuation from a text:\n",
    "1. we'd created an empty list\n",
    "2. char for char in text means whatever msg or text we pass 'char' starts traversing and \n",
    "3. if not in string .punctuation means check for the characters which are not present in punctuation signs , basically it          compares the characters with punctuation signs.\n",
    "4. Then, cleaned data'll join with that empty list and return the cleaned text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b727547",
   "metadata": {},
   "source": [
    "# Step-II:\n",
    "\n",
    "Add cleaned text column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72329681",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_text'] = data['Message'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7982934c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Message</th>\n",
       "      <th>Length</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>196</td>\n",
       "      <td>Ive been searching for the right words to than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>77</td>\n",
       "      <td>Even my brother is not like to speak with me T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!!</td>\n",
       "      <td>36</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                                            Message  Length  \\\n",
       "0      1  I've been searching for the right words to tha...     196   \n",
       "1      0  Free entry in 2 a wkly comp to win FA Cup fina...     155   \n",
       "2      1  Nah I don't think he goes to usf, he lives aro...      61   \n",
       "3      1  Even my brother is not like to speak with me. ...      77   \n",
       "4      1               I HAVE A DATE ON SUNDAY WITH WILL!!!      36   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  Ive been searching for the right words to than...  \n",
       "1  Free entry in 2 a wkly comp to win FA Cup fina...  \n",
       "2  Nah I dont think he goes to usf he lives aroun...  \n",
       "3  Even my brother is not like to speak with me T...  \n",
       "4                  I HAVE A DATE ON SUNDAY WITH WILL  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaede26",
   "metadata": {},
   "source": [
    "# Step-III:\n",
    "* Tokenization: Process of converting the normal string data into a list of tokens (also known as lemmas).\n",
    " OR\n",
    "* It consists of splitting an entire text into small units (tokens)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160494c6",
   "metadata": {},
   "source": [
    "# CountVectorizer :\n",
    "* It'll help us convert a collection of text documents to a vector of token counts.\n",
    "* That counts the number of times a word was mentioned in doucuments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c011c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bfa20df",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_object = CountVectorizer(stop_words=\"english\")  # CountVectorizer(stop_words = 'english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e86aea",
   "metadata": {},
   "source": [
    " Stopwords are the words in any language which does not add much meaning to a sentence. They are the words which are very common in text documents such as a, an, the, you, your, etc. The Stop Words highly appear in text documents. However, they are not being helpful for text analysis in many of the cases, So it is better to remove from the text. We can focus on the important words if stop words have removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b5731e",
   "metadata": {},
   "source": [
    "# Step-IV:\n",
    "Splitting x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c704b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['cleaned_text'].values\n",
    "y = data['Class'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2428b337",
   "metadata": {},
   "source": [
    "### Oues:\n",
    "can numpy array we used to hold string objects? yes. but the functions of Numpy \n",
    "library cannot performed on the string object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b528af0",
   "metadata": {},
   "source": [
    "### Splitting training and testing data:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5f6b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "946719fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x , y , random_state = 42 , test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ebacd5",
   "metadata": {},
   "source": [
    "### Creating the vectors of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3934ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_CV = CV_object.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c01c8169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4453x8216 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 34481 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab1bb14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x8216 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_CV.getrow(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371a7965",
   "metadata": {},
   "source": [
    "### Training a model\n",
    "\n",
    "With messages represented as vectors, we can finally train our spam/ham classifier. Now we can actually use almost any sort of classification algorithms. For a variety of reasons, the Naive Bayes classifier algorithm is a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a3075a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee8298f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f1ac70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_model.fit(x_train_CV,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a228a01",
   "metadata": {},
   "source": [
    "### Prediction/Testing the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89dacb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_CV = CV_object.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3ae37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = NB_model.predict(x_test_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e96fdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3db1689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cfb4811b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       145\n",
      "           1       0.99      0.99      0.99       969\n",
      "\n",
      "    accuracy                           0.99      1114\n",
      "   macro avg       0.98      0.98      0.98      1114\n",
      "weighted avg       0.99      0.99      0.99      1114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c72c955",
   "metadata": {},
   "source": [
    "# Spam Filtering Application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce86c775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter any mail: Hello and welcome to this course What is Machine Learning?  \n",
      "Check your inbox\n"
     ]
    }
   ],
   "source": [
    "msg = input('Enter any mail: ')\n",
    "msg_input = CV_object.transform([msg])\n",
    "predict = NB_model.predict(msg_input)\n",
    "\n",
    "if (predict[0] == 0):\n",
    "    print('Mail will go to the spam folder')\n",
    "else:\n",
    "    print('Check your inbox')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2147a4",
   "metadata": {},
   "source": [
    "# Tfidf :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd912280",
   "metadata": {},
   "source": [
    "### In **BOW approach** we saw so far, all the words in the text are treated equally important. There is no notion of some words in the document being more important than others. TF-IDF addresses this issue. It aims to quantify the importance of a given word relative to other words in the document and in the \n",
    "\n",
    "\n",
    "<font color=darkviolet>  **Term Frequency (tf)** </font>\n",
    "TF: Term Frequency, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization:\n",
    "\n",
    "TF(t) = (Number of times term 't' appears in a document) / (Total number of terms in the document).\n",
    "\n",
    "\n",
    "\n",
    "<font color=darkviolet>  **Inverse Document Frequency (idf)** </font>\n",
    "              It measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following:\n",
    "\n",
    "IDF(t) = log_e(Total number of documents / Number of documents with term t in it).corpus. It was commonly used representation scheme for information retrieval systems, for extracting relevant documents from a corpus for given text query.\n",
    "\n",
    "\n",
    "\n",
    "__Let's see an example:__\n",
    "\n",
    "Consider a document containing 100 words wherein the word cat appears 3 times. \n",
    "\n",
    "The term frequency (i.e., tf) for cat is then (3 / 100) = 0.03. \n",
    "\n",
    "Now, assume we have 10 million documents and the word cat appears in one thousand of these. \n",
    "\n",
    "Then, the inverse document frequency (i.e., idf) is calculated as log(10,000,000 / 1,000) = 4. \n",
    "\n",
    "Thus, the Tf-idf weight is the product of these quantities: 0.03 * 4 = 0.12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0141f8a0",
   "metadata": {},
   "source": [
    "# Step-I: Splitting x and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13d97ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['cleaned_text'].values\n",
    "y= data['Class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea14c948",
   "metadata": {},
   "source": [
    "# Step-II : Creating vectors using TF-IDF technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1baaa2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## text preprocessing and feature vectorizer\n",
    "# To extract features from a document of words, we import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_object = TfidfVectorizer()   ## objectcreation.\n",
    "x = tfidf_object.fit_transform(x)    ## fitting and transforming the data into vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b726756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['campus', 'camry', 'can', 'canada', 'canal', 'canary', 'cancel',\n",
       "       'canceled', 'cancelled', 'cancer', 'candont', 'canlove', 'canname',\n",
       "       'cannot', 'cannt', 'cant', 'cantdo', 'canteen', 'capacity',\n",
       "       'capital', 'cappuccino', 'caps', 'captain', 'captaining', 'car',\n",
       "       'card', 'cardiff', 'cardin', 'cards', 'care', 'careabout', 'cared',\n",
       "       'career', 'careful', 'carefully', 'careinsha', 'careless',\n",
       "       'carente', 'cares', 'careswt', 'careumma', 'carewhoever', 'caring',\n",
       "       'carlie', 'carlin', 'carlos', 'carlosll', 'carly', 'carolina',\n",
       "       'caroline', 'carpark', 'carry', 'carryin', 'cars', 'carso',\n",
       "       'cartons', 'cartoon', 'case', 'cash', 'cashbalance', 'cashbincouk',\n",
       "       'cashed', 'cashin', 'cashto', 'casing', 'cast', 'casting',\n",
       "       'castor', 'casualty', 'cat', 'catch', 'catches', 'catching',\n",
       "       'categories', 'caught', 'cause', 'causes', 'causing', 'caveboy',\n",
       "       'cbe', 'cc', 'cc100pmin', 'ccna', 'cd', 'cdgt', 'cds', 'cedar',\n",
       "       'ceiling', 'celeb', 'celeb4', 'celebrate', 'celebrated',\n",
       "       'celebration', 'celebrations', 'cell', 'census', 'center',\n",
       "       'centre', 'century', 'cer', 'cereals', 'ceri', 'certainly',\n",
       "       'certificate', 'cha', 'chachi', 'chad', 'chain', 'challenge',\n",
       "       'challenging', 'champ', 'champlaxigating', 'champneys', 'chance',\n",
       "       'chances', 'change', 'changed', 'changes', 'changing', 'channel',\n",
       "       'chapel', 'chaps', 'chapter', 'character', 'characters', 'charge',\n",
       "       'charged', 'charged150pmsg2', 'charges', 'charity', 'charles',\n",
       "       'charlie', 'charming', 'chart', 'charts', 'chase', 'chasing',\n",
       "       'chastity', 'chat', 'chat80155', 'chatim', 'chatlines', 'chatter',\n",
       "       'chatting', 'cheap', 'cheaper', 'cheat', 'cheating', 'chechi',\n",
       "       'check', 'checkboxes', 'checked', 'checkin', 'checking',\n",
       "       'checkmate', 'checkup', 'cheek', 'cheer', 'cheered', 'cheers',\n",
       "       'cheery', 'cheese', 'cheesy', 'cheetos', 'chef', 'chennai',\n",
       "       'chennaibecause', 'chennaii', 'cheque', 'cherish', 'cherthalain',\n",
       "       'chess', 'chest', 'chex', 'cheyyamoand', 'chez', 'chg', 'chic',\n",
       "       'chick', 'chicken', 'chickened', 'chief', 'chik', 'chikku',\n",
       "       'chikkuali', 'chikkub', 'chikkudb', 'chikkugoing', 'chikkuil',\n",
       "       'chikkuk', 'chikkusimple', 'chikkuwat', 'child', 'childish',\n",
       "       'childporn', 'children', 'childs', 'chile', 'chill', 'chillaxin',\n",
       "       'chillin', 'china', 'chinatown', 'chinchillas', 'chinese',\n",
       "       'chinky', 'chiong', 'chip', 'chitchat', 'chk', 'chloe',\n",
       "       'chocolate', 'choice', 'choices', 'choose', 'choosing', 'chop',\n",
       "       'chords', 'chores', 'chosen', 'chrgd50p', 'christ', 'christians',\n",
       "       'christmas', 'christmasmerry', 'christmassy', 'chuck', 'chuckin',\n",
       "       'church', 'ciao', 'cin', 'cine', 'cinema', 'citizen', 'city',\n",
       "       'citylink', 'cl', 'claim', 'claimcode', 'claims', 'claire',\n",
       "       'clarification', 'clarify', 'clas', 'clash', 'class', 'classes',\n",
       "       'classic', 'classmates', 'claypot', 'cld', 'clean', 'cleaning',\n",
       "       'clear', 'cleared', 'clearer', 'clearing', 'clearly', 'clever',\n",
       "       'click', 'cliff', 'cliffs', 'clip', 'clock', 'clocks', 'clos1',\n",
       "       'close', 'closeby', 'closed', 'closedincluding', 'closer',\n",
       "       'closes', 'closingdate040902', 'cloth', 'clothes', 'cloud',\n",
       "       'clover', 'club', 'club4', 'club4mobilescom', 'clue', 'cm', 'cme',\n",
       "       'cmon', 'cn', 'cnl', 'cnn', 'co', 'coach', 'coast', 'coat',\n",
       "       'coaxing', 'cocacola', 'coccooning', 'cochin', 'cock',\n",
       "       'cocksuckers', 'coco', 'code', 'code4xx26', 'coffee', 'coherently',\n",
       "       'coimbatore', 'coin', 'coincidence', 'coins', 'colany', 'cold',\n",
       "       'coldheard', 'colin', 'collages', 'collapsed', 'colleagues',\n",
       "       'collect', 'collected', 'collecting', 'collection', 'colleg',\n",
       "       'college', 'collegexx', 'color', 'colour', 'colourful',\n",
       "       'colourredtextcolourtxtstar', 'colours', 'com', 'comb',\n",
       "       'combination', 'combine', 'come', 'comedy', 'comedycant', 'comei',\n",
       "       'comes', 'cometil', 'comfey', 'comfort', 'comin', 'coming',\n",
       "       'comingdown', 'comingtmorow', 'command', 'comment', 'commercial',\n",
       "       'commit', 'common', 'community', 'comp', 'companies', 'companion',\n",
       "       'company', 'compare', 'compass', 'compensation', 'competition',\n",
       "       'complacent', 'complain', 'complaining', 'complaint',\n",
       "       'complementary', 'complete', 'completed', 'completely',\n",
       "       'completes', 'completing', 'complexities', 'complimentary',\n",
       "       'compliments', 'compofstuff', 'comprehensive', 'compromised',\n",
       "       'compulsory', 'computational', 'computer', 'computerless',\n",
       "       'computers', 'comuk220cm2', 'conacted', 'concentrate',\n",
       "       'concentrating', 'concentration', 'concern', 'concerned',\n",
       "       'concert', 'conclusion', 'condition', 'conditionand', 'conditions',\n",
       "       'conducts', 'conected', 'conference', 'confidence', 'configure',\n",
       "       'confirm', 'confirmd', 'confirmdeny', 'confirmed', 'conform',\n",
       "       'confused', 'confuses', 'congrats', 'congratulations', 'connect',\n",
       "       'connected', 'connection', 'connections', 'cons', 'consensus',\n",
       "       'consent', 'conserve', 'consider', 'considering', 'consistently',\n",
       "       'console', 'constant', 'constantly', 'contact', 'contacted',\n",
       "       'contacts', 'contains', 'content', 'contented', 'contention',\n",
       "       'contents', 'continent', 'continue', 'continued', 'contract',\n",
       "       'contribute', 'control', 'convenience', 'conversations',\n",
       "       'converted', 'converter', 'convey', 'conveying', 'convince',\n",
       "       'convinced', 'convincing', 'convincingjust', 'cook', 'cooked',\n",
       "       'cookies', 'cooking', 'cool', 'coolmob', 'cooped', 'cooperative',\n",
       "       'copied', 'copies', 'coping', 'cops', 'copy', 'corect', 'cornwall',\n",
       "       'corporation', 'corrct', 'correct', 'correction', 'correctionor',\n",
       "       'correctly', 'corrupt', 'corvettes', 'cos', 'cosign', 'cost',\n",
       "       'costa', 'costing', 'costs', 'costume', 'costumes', 'couch',\n",
       "       'cougarpen', 'cough', 'coughing', 'could', 'coulda', 'couldn',\n",
       "       'couldnt', 'count', 'countin', 'countinlots', 'country', 'counts',\n",
       "       'coupla', 'couple', 'courage', 'courageous', 'course', 'court',\n",
       "       'courtroom', 'cousin', 'cover', 'coveragd', 'covers', 'coz',\n",
       "       'cozsomtimes', 'cozy', 'cps', 'cr', 'cr01327bt', 'cr9', 'crab',\n",
       "       'crack', 'craigslist', 'crammed', 'cramps', 'crap', 'crash',\n",
       "       'crashed', 'crashing', 'crave', 'craving', 'craziest', 'crazy',\n",
       "       'crazyin', 'cream', 'created', 'creative', 'creativity', 'cred',\n",
       "       'credit', 'credited', 'credits', 'creep', 'creepy', 'cresubi',\n",
       "       'cribbs', 'cricket', 'cricketer', 'crickiting', 'cried', 'crisis',\n",
       "       'crisisspk', 'cro1327', 'crore', 'cross', 'crossing', 'crowd',\n",
       "       'croydon', 'crucial', 'crucify', 'cruise', 'cruisin', 'crushes',\n",
       "       'cry', 'crying', 'cs', 'csh11', 'cst', 'cstore', 'ctagg', 'ctargg',\n",
       "       'cthen', 'ctla', 'cttargg', 'ctter', 'cttergg', 'cu', 'cuck',\n",
       "       'cud', 'cuddle', 'cuddled', 'cuddling', 'cudnt', 'culdnt',\n",
       "       'cultures', 'cum', 'cumin', 'cumming', 'cup', 'cupboard', 'cuppa',\n",
       "       'curfew', 'curious', 'current', 'currently', 'curry', 'curtsey',\n",
       "       'cust', 'custcare', 'custcare08718720201', 'custom', 'customer',\n",
       "       'customercare', 'customers', 'customersqueriesnetvisionukcom',\n",
       "       'cut', 'cute', 'cutefrnd', 'cutest', 'cutie', 'cutter', 'cutting',\n",
       "       'cuz', 'cw25wx', 'cya', 'cyclists', 'cysts', 'da', 'daal',\n",
       "       'daalways', 'dabbles', 'dabooks', 'dad', 'daddy', 'dado', 'dads',\n",
       "       'dagood', 'dahe', 'dahow', 'dai', 'daily', 'dajst', 'dammit',\n",
       "       'damn', 'dan', 'danalla', 'dancce', 'dance', 'dancin', 'dancing',\n",
       "       'dane', 'dang', 'danger', 'dangerous', 'dao', 'daplease', 'dare',\n",
       "       'dark', 'darker', 'darkest', 'darkness', 'darlin', 'darling',\n",
       "       'darlings', 'darlinim', 'darren', 'dartboard', 'das', 'dasara',\n",
       "       'dat', 'data', 'date', 'datebox1282essexcm61xn', 'dates', 'dating',\n",
       "       'datingi', 'datoday', 'dats', 'datz', 'daurgent', 'dave',\n",
       "       'dawhats', 'dawhere', 'dawns', 'day', 'day2', 'day2find',\n",
       "       'dayexcept', 'dayhas', 'days', 'dayshe', 'daysso', 'dayswill',\n",
       "       'daysèn', 'daytime', 'dayu', 'daywith', 'dd', 'de', 'dead',\n",
       "       'deadwell', 'deal', 'dealer', 'dealers', 'dealfarm', 'dealing',\n",
       "       'deals', 'deam', 'dear', 'dear1', 'dearer', 'deari', 'dearloving',\n",
       "       'dearly', 'dearme', 'dearrakhesh', 'dearregret', 'dearshall',\n",
       "       'dearslp', 'deartake', 'deary', 'death', 'debating', 'dec',\n",
       "       'decades', 'december', 'decide', 'decided', 'deciding', 'decimal',\n",
       "       'decision', 'decisions', 'deck', 'decking', 'declare',\n",
       "       'decorating', 'dedicate', 'dedicated', 'deduct', 'deep', 'deepak',\n",
       "       'deepest', 'deer', 'deeraj', 'def', 'defeat', 'defer', 'definite',\n",
       "       'definitely', 'definitly', 'defo', 'degree', 'degrees',\n",
       "       'dehydrated', 'dehydration', 'del', 'delay', 'delayed', 'delete',\n",
       "       'deleted', 'delhi', 'delicious', 'deliver', 'delivered',\n",
       "       'deliveredtomorrow', 'delivery', 'deltomorrow', 'deluxe', 'dem',\n",
       "       'demand', 'den', 'dena', 'dengra', 'denis', 'dent', 'dental',\n",
       "       'dentist', 'dentists', 'denying', 'department', 'dependable',\n",
       "       'dependents', 'depends', 'deposit', 'deposited', 'depressed',\n",
       "       'depression', 'dept', 'der', 'derek', 'dereks', 'derp', 'describe',\n",
       "       'description', 'desert', 'deserve', 'designation', 'desires',\n",
       "       'desk', 'desparate', 'desparately', 'desperate', 'despite',\n",
       "       'dessert', 'destination', 'destiny', 'detail', 'detailed',\n",
       "       'details', 'detailsi', 'determine', 'determined', 'detroit',\n",
       "       'deus', 'develop', 'developed', 'developer', 'device', 'devils',\n",
       "       'devouring', 'dey', 'deyhope', 'deyi', 'dha', 'dhina', 'dhoni',\n",
       "       'dhorte', 'di', 'dial', 'dialling', 'dialogue', 'diamond',\n",
       "       'diamonds', 'diapers', 'dice', 'dick', 'dict', 'dictionary', 'did',\n",
       "       'diddy', 'didn', 'didnt', 'didntgive', 'didt', 'die', 'died',\n",
       "       'diesel', 'diet', 'dieting', 'diff', 'differ', 'differbe',\n",
       "       'difference', 'differences', 'different', 'difficult',\n",
       "       'difficulties', 'dificult', 'digi', 'digital', 'digits', 'dignity',\n",
       "       'dileepthank', 'dime', 'dimension', 'din', 'dine', 'dined',\n",
       "       'dinero', 'ding', 'dining', 'dinner', 'dinnermsg', 'dino', 'dint',\n",
       "       'dippeditinadew', 'dips', 'direct', 'directly', 'director',\n",
       "       'directors', 'dirt', 'dirtiest', 'dirty', 'dis', 'disagreeable',\n",
       "       'disappeared', 'disappointment', 'disaster', 'disasters',\n",
       "       'disastrous', 'disc', 'disclose', 'disconnect', 'disconnected',\n",
       "       'discount', 'discreet', 'discuss', 'discussed', 'diseases',\n",
       "       'diskyou', 'dislikes', 'dismay', 'dismissial', 'display',\n",
       "       'distance', 'distract', 'disturb', 'disturbancemight',\n",
       "       'disturbing', 'ditto', 'divert', 'division', 'divorce', 'diwali',\n",
       "       'dizzamn', 'dizzee', 'dl', 'dled', 'dlf', 'dload', 'dnt', 'do',\n",
       "       'dob', 'dobby', 'dobbys', 'doc', 'dock', 'docks', 'docs', 'doctor',\n",
       "       'doctors', 'documents', 'dodda', 'dodgey', 'does',\n",
       "       'doesdiscountshitinnit', 'doesn', 'doesnt', 'dog', 'dogbreath',\n",
       "       'dogg', 'doggin', 'dogging', 'doggy', 'dogs', 'dogwood', 'doin',\n",
       "       'doinat', 'doing', 'doinghow', 'doingwhat', 'doinnearly',\n",
       "       'dointerested', 'doke', 'dokey', 'dollar', 'dollars', 'dolld',\n",
       "       'dolls', 'dom', 'domain', 'don', 'donate', 'done', 'donewant',\n",
       "       'donno', 'dont', 'dont4get2text', 'dontcha', 'dontignore',\n",
       "       'dontplease', 'donyt', 'dooms', 'door', 'doors', 'dorm',\n",
       "       'dormitory', 'dorothykiefercom', 'dose', 'dosomething', 'dot',\n",
       "       'double', 'doublefaggot', 'doublemins', 'doubles', 'doubletxt',\n",
       "       'doubt', 'doug', 'dough', 'down', 'download', 'downloaded',\n",
       "       'downloads', 'downon', 'downs', 'downstem', 'dozens', 'dps', 'dr',\n",
       "       'dracula', 'drama', 'dramastorms', 'dramatic', 'drastic', 'draw',\n",
       "       'drawplease', 'draws', 'dreading', 'dream', 'dreamlove', 'dreams',\n",
       "       'dreamsmuah', 'dreamstake', 'dreamsu', 'dreamz', 'dress',\n",
       "       'dressed', 'dresser', 'drink', 'drinkin', 'drinking', 'drinkpa',\n",
       "       'drinks', 'drive', 'driver', 'drivin', 'driving'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print feature names selected from the raw documents\n",
    "tfidf_object.get_feature_names_out()[2000:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38e5fc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9537"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_object.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e9b0af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the feature vectors:\n",
    "x = x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "584afbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d7813f",
   "metadata": {},
   "source": [
    "# Step-III: Split data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d1113da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state =42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656070dd",
   "metadata": {},
   "source": [
    "# Step-IV: Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2a967e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5a0fe7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e152dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0005019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "543c5ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1\n",
       "row_0          \n",
       "0      100   45\n",
       "1        0  969"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test,y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7b79de",
   "metadata": {},
   "source": [
    "* It can be seen that the False positive counts are 0 so our model is performing well and good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26ac1cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.69      0.82       145\n",
      "           1       0.96      1.00      0.98       969\n",
      "\n",
      "    accuracy                           0.96      1114\n",
      "   macro avg       0.98      0.84      0.90      1114\n",
      "weighted avg       0.96      0.96      0.96      1114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80545c03",
   "metadata": {},
   "source": [
    "# Spam Filtering Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4515b66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter any msg: Hello and welcome to this course What is Machine Lear\n",
      "Check Inbox\n"
     ]
    }
   ],
   "source": [
    "msg = input('Enter any msg: ')\n",
    "msgInput = tfidf_object.transform([msg])\n",
    "prediction = nb.predict(msgInput)\n",
    "\n",
    "if prediction[0]==0:\n",
    "    print('It\\'ll go to the spam folder')\n",
    "else:\n",
    "    print('Check Inbox')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36e6e7f",
   "metadata": {},
   "source": [
    "### Pros of Naive Bayes\n",
    "\n",
    "- Naive Bayes Algorithm is a fast, highly scalable algorithm\n",
    "- Naive Bayes can be classified for both binary classification and multi class classification. It provides different types of Naive Bayes Algorithms like GaussianNB, MultinominalNB, BernoulliNB.\n",
    "- It is simple algorithm that depends on doing a bunch of count.\n",
    "- Great choice for text classification problems. it's a popular choice for spam email classification.\n",
    "- It can be easily trained on small datasets.\n",
    "- Naive Bayes can handle misssing data, as they ignored when a probabilty is calculated for a class value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5794d2",
   "metadata": {},
   "source": [
    "### Cons of Naive Bayes\n",
    "\n",
    "- It considers all the features to be unrelated, so it cannot learn the relationship between features. This limits the applicability of this algorithm in real-world use cases.\n",
    "- Naive Bayes can learn individual featutre importance but can't determine the relationship among features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc00e7",
   "metadata": {},
   "source": [
    "## Application of Naive Bayes\n",
    "\n",
    "##### Text classification / spam filtering / Sentiment analysis:\n",
    " - Naive Bayes classifiers mostly used in text classification\n",
    " - News article classification SPORTS, TECHNOLOGY etc.\n",
    " - Spam or Ham: Naive Bayes is the most popular method for mail filtering\n",
    " - Sentiment analysis focuses on identifying whether the customers think positively or negatively about a certain topic (product or service).\n",
    " \n",
    " \n",
    "##### Recommendation System:\n",
    "- Naive Bayes classifier and Collabrative filtering together buids a recommendation system that uses machine learning and data mining techniques to filter unseen information and predict whether a user would like a given resource or not. \n",
    "\n",
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505188a7",
   "metadata": {},
   "source": [
    "### 3 Types of Naive Bayes in Scikit Learn\n",
    "\n",
    "__Gaussian__\n",
    "\n",
    "- It is used in classification and it assumes that features follow a normal distribution.\n",
    "\n",
    "__Multinominal__\n",
    "- It is used for discrete counts. For eg., let's say we have a text cLassification problem. Here we consider Bernoulli trails which is one step further and instead of \"word occuring in the document\", we have \"count how often word occurs in the document\" you can think of it as \"number of times outcome number_x is observed over n trails\".\n",
    "\n",
    "__Bernoulli__\n",
    "- The binomial model is useful if your feature vectors are binary (ie., Zeroes and One). One application would be text classification with 'bag of words' model where the 1s and 0s are \"words occur in the document\" and \"word does not occur in the document\" respectively.### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04f714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
